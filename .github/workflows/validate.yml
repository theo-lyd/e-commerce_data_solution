name: Data Pipeline Validation

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  build-and-validate:
    runs-on: ubuntu-latest
    
    # Key Fix: Set a default working directory for all run commands in this job
    defaults:
      run:
        working-directory: ./

    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Cache Pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        # This command will now correctly find requirements.txt at the root
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run ETL & Data Quality Pipeline
        # This command will also run from the root, so script paths must be full
        run: python scripts/etl_pipeline.py

      - name: Upload Data Warehouse Artifact
        uses: actions/upload-artifact@v3
        with:
          name: olist-data-warehouse
          path: output/olist_master.parquet